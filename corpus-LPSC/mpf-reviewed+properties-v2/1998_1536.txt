SUPER-RESOLUTION RESULTS FROM PATHFINDER IMP.  B. Kanefsky,1 T.J. Parker,2 and P.C. Cheeseman3. 1kanef@ptolemy.arc.nasa.gov, Caelum, NASA Ames, M/S 269-2, Moffett Field CA 94035, 2JPL, 3RIACS, NASA Ames. During the Pathfinder primary and extended mission, the NASA Ames super-resolution image processing algorithm [1,2] was successfully used to obtain processed images at resolutions several times higher than the raw IMP images. In addition to this automatic processing, a human-guided emulation of part of the algorithm was performed by Tim Parker using Adobe Photoshop® during and after the mission.  Both techniques generally yielded dramatic improvements.  The automated algorithm has achieved significantly better results than the manual one in some cases, but in others, the advantage of having human perception in the loop outweighed the additional processing that the automated algorithm does. Nineteen sequences especially designed for superresolution processing were acquired [3].  The nine targets were divided fairly evenly between nearby rocks and horizon features.  More sequences were planned to immediately follow the completion of the Super Pan, had the spacecraft survived that long. The processing was automated during the extended mission, so that the results appeared on the science team's internal web site with no human intervention once the raw images were available. All sequences show significant, often spectacular, improvements in resolution.  For example, in raw, noncompressed IMP images of Wedge, the rock's texture was not well resolved and appeared to be bumpy; it could have been interpreted to be a coarse, sedimentary rock. The super-resolved images on Sol 20 made it clear that the bumps are actually pits — perhaps vesicles or sockets. Wedge was chosen specifically because we anticipated ground truth from Sojourner images, and indeed, when the rover first approached Wedge on Sol 35 and took closeups from centimeters away, the pitted texture was confirmed.  For horizon features such as both Twin Peaks, and for several rocks, the super-resolved images will remain the clearest available for the foreseeable future. The super-resolution algorithm produced improvements more reliably from Pathfinder IMP images than it had on the archival Viking Orbiter data we presented here in 1994 [1].  This is partly due to the better quality of camera, but also due to fact that the camera was in a fixed location, simplifying the subpixel registration search problem by eliminating rotation and scaling.  Twenty-five images were acquired, with the camera commanded to move between images and then return to exactly the same pointing.  Since the camera's pointing imprecision is greater than one pixel (far greater, in this case), this technique ensured that the range of possible fractional pixel motions was sampled randomly. The improvement in resolution is not free; it requires repeated samples (images) of the target, and thus consumes at least as much downlink bandwidth as would be required if the camera had a zoom lens and sent back a highresolution image.  Fortunately, Pathfinder-DSN communication achieved a higher bandwidth than anticipated. Also, the IMP camera software offered flexibility in choosing a subframe size.  A minimum size of about 10x20 pixels was needed to ensure overlap, due to IMP's pointing uncertainty, but in practice, larger sizes were chosen, to satisfy the geomorphology group's desire to obtain high-resolution context surrounding the target. The Super-Pan and Multi-Spectral Spot sequences, though not designed for super-resolution, apparently have sufficient subpixel-scale motion, even though some of them were taken without commanding the camera to move.  We attribute this to small displacements in pointing due to jarring of the camera head within the gear-head backlash, and/or to tiny optical misalignments from one filter to another.  Ironically, this imprecision is what enables high-precision results, by providing multiple independent samples.  Super-Pan images were acquired through all 15 color filters, with very little compression. The color differences pose a problem automated processing, since the registration and averaging algorithms were designed for use with essentially identical images.  They pose no problem for the human registration technique. The human-guided Photoshop technique is as follows: Each image, through every color filter and both eyes, is imported into Photoshop as a layer.  Each layer is enlarged 1000%, using bicubic interpolation to smooth out the discontinuities at pixel edges. Each layer is then sharpened using unsharp mask filtering with a 5 pixel SUPER-RESOLUTION:  B. Kanefsky, T. J. Parker, and P. C. Cheeseman radius, 0 threshold, and 100% contrast between adjacent pixels.  These values were empirically chosen to achieve the best overall results for this dataset. For certain targets, such as Mini Matterhorn, higher radius values were used, and the unsharp mask filtering was sometimes run twice on certain colors, to bring out detail within a rock.  This usually produces more objectionable artifacts at highcontrast edges, however, and so doesn't work well for distant targets. Each layer is then co-registered to the red layer by "blinking" it on and off (using the eye icon in the Layers palette) while moving it one pixel at a time (one-tenth pixel in the original images).  When all layers are registered, they are averaged together by weighting their opacities in proportion to the total number of layers. The composite image is then reduced to 50% of its size, or 500% of the original size, before saving.  The details, and further results, are presented in Parker's abstract. [4] The above manual technique is essentially identical to the automatic super-resolution algorithm, except that the latter has no unsharp-mask step and was run, in this case, to one-fifth pixel precision instead of one-tenth. The manual technique would need to be modified somewhat, or use a different registration tool than Photoshop, to be used with orbiter cameras.  Lander images can be co-registered with two translation parameters (x and y), whereas orbiter images generally require full affine transforms, including rotation and scaling.  While Photoshop 4.0 provides an interactive interface for general affine transforms, it does not allow "blinking" the reference layer on and off while adjusting the transform.  In contrast, the automated program is designed to be compiled for either translationonly or full affine transform searches, though it tends to be more reliable when it has only the two degrees of freedom. Both the manual and the automatic super-resolution techniques take advantage of the fact that each image is an independent sample of the same scene, and so the scene is oversampled.  The pixels from each image do not exactly overlay each other, due to pointing imprecision; thus, they sample the scene differently. Both super-resolution methods try to reconstruct the reflectivity of the actual surface from these independent samples, by co-registering the images to subpixel accuracy (automatically or manually) and then averaging them.  The automatic NASA Ames algorithm then goes a step further.  Based on a crude model of the camera imaging process for each image, it attempts to invert the point-spread function introduced by the camera by using an iterative deconvolution process inspired by Bayesian theory.  It then reregisters the original inputs against the sharper result to attain a more precise registration, and repeats the whole process several times to converge on a final output. The need to prepare command sequences for superresolution also presented an opportunity to experiment with some simple ground automation.  A custom sequence generator with a web form interface was used, beginning with the fifth sequence.  It not only embodied the tricks needed to obtain reproducible IMP pointing and sufficiently independent samples, but also provided a convenient way to select camera parameters for any type of one-spot image sequence.  The scientist located the desired target in an earlier image, e.g. from the Gallery Pan, using any image tool, then entered the image id and coordinates, and filled in the choices on the rest of the form.  A text file of spacecraft commands (SASF) was automatically produced, along with the paperwork required by the IMP team, complete with a small image confirming the selected target.  The server was a Symbolics Lisp Machine, and was accessed through Netscape on a Macintosh, SGI, or SUN at JPL.  Later, once the raw images were acquired, downlinked, and assembled, the processing was also automated: the Lisp Machine wrote a script, told a SUN to run it, and wrote JPEG and HTML files as the SUN signaled that the images were ready, resulting in a web page on the internal Pathfinder science team site. This was a step toward minimizing the labor involved before scientific analysis could begin, and would have allowed superresolution sequencing and processing to continue no matter how long the mission had lasted. Both the manual and the automated technique yielded tremendous improvement in spatial resolution, and we feel that some version of this algorithm should be considered on future non-flyby missions with fixed resolution imaging and sufficient downlink bandwidth.  Of the two, the human-guided processing is more flexible, but unattended processing would have been an advantage had the extended mission lasted a month or so longer and begun returning several super-resolution sequences per day. All super-resolution images are planned for inclusion on the Pathfinder Derived Products CD-ROM, scheduled for release this year, and we hope the enhanced images will prove useful to the science community. [1] Cheeseman, P. et al., "Subpixel Resolution from Multiple Images," in LPSC XXV, pp 241-242, 1994. [2] Cheeseman, P. et al., in Maximum Entropy and Bayesian Methods, G. R. Heidbreder (ed.), 293-308, Kluwer, the Netherlands, 1996. [3] Helpful advice on the IMP camera and its pointer were given by several members of the science team, including R. Kirk, L. Soderblom, M. Malin, and J. Maki, The targets were selected by the geomorphology group, with input from the entire team. [4] Parker, T.J., " 'Super Resolution' of the Mars Pathfinder Landing Site, Using Manual Techniques," in LPSC XXIX, 1998. 
