 THE SUPERRESOLVED SUPER PAN: IMPROVED RESOLUTION OF THE MARS PATHFINDER LANDING SITE USING SUPERRESOLUTION ON THE IMP SUPER PAN DATA SET  Carol Stoker1 and Bob Kanefsky2, 1M.S. 245-3 NASA Ames Research Center, Moffett Field, CA 94035, cstoker@mail.arc.nasa.gov; M.S. 269-2 NASA Ames Research Center, Moffett Field, CA 94035, kanef@artemis.arc.nasa.gov   Introduction: Superresolution [1,2,3] is an image processing technique that provides improved image resolution by combining data from multiple independent, but essentially identical, lower resolution images.  The improvement in resolution results from using the starting images as independent samples of the object and performing a deconvolution to remove the camera's point spread function and other image distortion effects.  Our Superresolution approach, based on Bayseian probability theory, constructs a model of the surface using parameters describing the observation system which, for images, includes the surface illumination, camera orientation, camera characteristics, optical distortion, and point spread function of the camera lens.  Input images should be identical samples of the same location on different parts of the CCD array.  The input images are first co-registered and co-added, then an inverse problem is solved which yields a model-result image of the surface.  This result is then co-registered with the input images and all images (result and input) are used to solve for a new model.  This iterative process is continued until the modelresult does not change. In theory, the method produces an improvement in resolution of a factor of n1/2 for n input images.  Approach: The Superresolution algorithm was applied to the Imager for Mars Pathfinder (IMP) Super Pan[4, 5, 6], a product that was designed to acquire image cubes using all 15 IMP filters at each camera position of a full landing site panorama.  The filters are distributed between the left and right eyes, but only filters from the same eye can be combined in Superresolution because the images in the left and right eyes are different due to stereo parallax.  Furthermore, spectral variation can be confused with subpixel information, so Superresolution will achieve good results only for images with little spectral variability. To determine which filters we could include in the Superresolution processing, we plotted data from each filter against each other filter for several Super Pan cubes.  In filters that are likely to combine well using Superresolution, the scatter plot of the data can be fit to a straight line.  We found that all filters except 440, 480 and 530 nm could be used.  Most results used 7 left eye (670,800,860,900,930, 965,1000 nm) and 4 right eye (600,670,750, 965nm) filter images as inputs.  Results: Superresolved results have been produced for all the Super Pan data acquired through the end of the Pathfinder mission. The processing was performed to provide a factor of two resolution improvement in all cases.  The number of images combined for a particular Superresolved image tile varies because all the data available were used, including images with missing packets.  In many cases, a complete image cube was not received in the downlink so the data were retaken.  We decided to include all the data in the processing to get the maximum possible improvement at each location. We found that over-sampling produces superior Superresolution results as compared to using the minimum number of theoretically-allowed samples, which often result in artifacts caused by slight misregistration of the input images.  The Superresolved images have been submitted to the PDS for permanent archive.  They are also posted on the world wide web at url: http://ic.arc.nasa.gov/ic/projects/bayesgroup/group/super-res/2d/mpf/.  The data are accessed via a unique interface; by clicking on a color panorama of the landing site at the desired location, the Superresolved image at the corresponding location is displayed, along with the input images which can be individually examined.  For the right eye, the Superresolved result can be viewed in color.  Color products were produced by registering the 530nm and 440nm-filter images against the grayscale Superresolved result and using them as the green and blue channels for the color product, and the grayscale Superresolved result as the red channel, producing an intermediate color image with a resolution somewhat degraded since the green and blue channels are of the original resolution.  To preserve the sharpness, the final color product is produced in intensity/hue/saturation (IHS) color space, using the Superresolution product as the intensity channel, and taking the hue and saturation channels from the intermediate color image.   The Superresolved results consistently show a resolution improvement over the input images, often revealing detail or additional information not otherwise visible. Some illustrative examples are shown below for near and far field images, and others will be shown in the poster.   Figure 1 shows the Color Superresolution of South Peak using 4 input images.  Color adds extra clues to composition.  Fine detail is seen in the light-colored features which, in the input images, appear to form bright lines running perpendicular to the slope of the peak.  These were originally interpreted to be benches or lines of boulders left by receding flood waters [3].  The color similarity between the bright-colored patch of soil at bottom left and the bright patches on the peak suggest that they may be drift material accumulated in depressions or may be areas relatively free of darker rocks that therefor appear brighter.    Figure 1.  South peak (l) example input image, (r) color superresolved result.  Figure 2 shows the Superresolution of Yogi prepared from 7 left-eye input images (b) along with the 670 nm input image for comparison (a).  This result image compares favorably with the best results from a manual Superresolution technique derived from our algorithm but implemented using THE SUPERRESOLVED SUPER PAN:  C. R. Stoker and B. Kanefsky  Photoshop [7].  Fine scale pits in Yogi are visible in the Superresolved result that are not visible in the input image.  Figure 2a input image at 670 nm.  Figure 2b Superresolved result.      Conclusions: Using Superresolution we have produced a improved the available spatial resolution of the Pathfinder landing site by a factor of  two in the area covered by the Super Pan (75% of the landing site).  While the resolution improvement is generally not as substantial as that previously obtained from image sequences specifically designed for Superresolution where 25 single filter images were processed [3], the Super Pan data set provides much more coverage at improved resolution. Also, we have produced color composites for this data set, and have not yet done so for the other data set.  Since resolution is a key factor in the interpretation of surface morphology, this product represents an asset for scientific analysis of the Pathfinder landing site.  References: [1] Cheeseman, P., et al. (1996), Maximum Entropy and Bayesian Methods, 293-308, Kluwer, Nederlands.  [2] Kanefsky, P.(1998), LPSC29, 1536.  [3] Stoker, C. et al.(1999), J.G.R. 104, 28557-28575.  [4] Gaddis, L. et al.(1998) LPSC 29, 1831-1832.  [5] Gaddis, L. et al. (1999) J. G.R. 104, 8853-8868.  [6] Smith, P. et al. (1997), J.G.R. 102, 4003-4025. [7] Parker,T.J. (1998) LPSC 29, 1817. Acknowledgements:  This work was sponsored by the Mars Pathfinder Data Analysis program administered for NASA by the Jet Propulsion Laboratory. 
