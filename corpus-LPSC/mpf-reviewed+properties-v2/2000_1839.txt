 HYPERSPECTRAL IMAGING EXPERIMENTS IN PREPARATION FOR UPCOMING MARS SURFACE MISSIONS.  J. E. Moersch1,  T. L. Roush2, and J. Farmer3, 1NASA Ames Research Center, MS 2394, Moffett Field, CA 94035-1000 (jmoersch@mail.arc.nasa.gov), 2NASA Ames Research Center, MS 245-3, Moffett Field, CA  94035-1000 (troush@mail.arc.nasa.gov), 3Geology Department, Arizona State University, Tempe, AZ  85287-1404 (jack.farmer@asu.edu).  Background:  Current plans for NASA's Mars Surveyor Program call for small thermal emission spectrometers (Mini-TES) to be sent to the martian surface on a fixed lander (2001 launch) and on rovers (2003 and 2005 launches) [1].  The Mini-TES operates in the 6-25 µm range with a selectable spot size of either 8 or 20 mrad.  Its primary purpose is to determine the mineralogic composition of rocks and soils surrounding the lander (or rover).  The Mini-TES is capable of observing targets at any azimuth angle, and between -50° to +30° elevation angle [2].  In addition to taking spot spectra of specific targets, plans call for the Mini-TES to acquire be rastered to build hyperspectral image cubes.  While hyperspectral cubes are commonly acquired from airborne and orbital platforms, little experience exists in the acquisition and analysis of such data products from the point of view of a lander or rover sitting on a planetary surface.  Here we present a subset of initial results from experiments we have carried out to simulate the type of data that will be returned from the martian surface. Experimental apparatus:  The spectrometer used in these experiments is an Analytical Spectral Devices FieldSpecFR portable field spectrometer.  This visible/near infrared (0.35 - 2.5 µm) spectrometer was chosen over thermal infrared spectrometers because of its relative ease of use and its ability to collect spectra via fiber optic.  The fiber optic from the spectrometer is connected to a small telescope mounted on a pointable tripod.  This telescope has a 17 mrad field of view, intermediate to the high- and low-resolution modes of the Mini-TES.  The telescope may be pointed with a boresighted rifle scope or by adding an automated pan/tilt platform to the tripod (see below). Early experiments:  Our first attempt at simulating acquisition of a Mini-TES-like hyperspectral cube was conducted at South Tufa Point, Mono Lake, CA (Fig. 1).  Two stadia rods were marked at intervals of 8.7 cm (17 mrad as viewed from a distance of 5 m).  Vertical and horizontal bubble levels mounted on the rods allowed us to precisely orient them orthogonally in the field.  The tripod was placed 5 m from the rods, and using the rifle scope, the spectrometer telescope was manually pointed at a mark on the vertical stadia rod as it was held at a marked station on the horizontal rod (Fig. 1, left panel).  The vertical rod was then removed and a spectrum was collected.  With the vertical rod back in place, the telescope was pointed to the next mark down the vertical rod, and the process was repeated until a full column of spectra was collected.  The vertical rod was then moved to the next horizontal position and another column was acquired, etc.  In this manner, a 15 x 10 pixel hyperspectral cube could be acquired in about 2.5 hours.              Figure 1 The upper right panel in Fig. 1 is a digital camera photo of the scene acquired in one hyperspectral image at South Tufa.  The lower right panel is a simple three-channel color composite from the hyperspectral image, with R=2.35µm, G=1.00µm, and B=0.35µm.  With this choice of channels, the sky appears bright blue because of the dominance of Rayleigh-scattering at short wavelengths, vegetation appears green because of the strong chlorophyll absorption edge that maximizes near 1 µm, and the carbonate tufa towers appear yellow. Automated pointing:  While the hyperspectral images acquired at South Tufa provided an interesting first-look at the type of observations envisioned for Mini-TES on Mars, they were labor and timeintensive to acquire.  A substantial improvement to this technique was achieved by placing a small computer-controlled motorized pan/tilt platform between the tripod and the telescope.  With the pan/tilt platform programmed to move the telescope one field-ofview every few seconds, much larger images could be collected in a shorter amount of time.         HYPERSPECTRAL IMAGING EXPERIMENTS:  J. E. Moersch et al.           Figure 2 The upper left panel in Fig. 2 is a digital camera image of a scene in the rover "sandbox" at NASA Ames, which has been salted with rocks of various compositions.  The upper right panel is a "natural color" (R=0.62µm, G=0.52µm, B=0.48µm) composite from a 30 x 15 pixel hyperspectral image of this scene.  Using the automated pan/tilt platform to point the spectrometer, this image was collected in less than half an hour. With the larger number of pixels in this image, some of the traditional statistical analysis techniques used in hyperspectral image processing may be applied.  Principle Component Analysis (PCA) is one type of transform commonly used to reduce the dimensionality of hyperspectral images and classify pixels with like spectral properties.  The lower left panel of Fig. 2 contains a color composite of three principle components from the same hyperspectral image.  Rocks of similar colors in this image are inferred to have similar compositions.  Yellow rocks in this image are also bright in the band ratio image of the lower right panel, where the 2.14µm channel has been divided by the 2.21µm channel.  These rocks show up in this ratio image because they are dominated by phyllosilicates, which have a deep absorption near 2.20 µm caused by the O-H overtone/combination vibrations. Superresolution hyperspectral images: The pointing system which will be used with the Mini-TES instrument has a precision of +/- 1 mrad [2], which is substantially smaller than even the high-resolution mode spot size of the instrument.  This affords an interesting possibility for data acquisition by subsampling the instrument's point spread function to achieve improved spatial resolution ("superresolution") in hyperspectral images.  A similar concept was employed in post-processing of images from the Mars Pathfinder mission by registering and co-adding several images of the same scene with random sub-pixel offsets [e.g., 3]. To study the viability of superresolution observations for the Mini-TES, we acquired two more hyperspectral images in the Ames sandbox.  The first was a 15 x 10 pixel image acquired in the same way as the image in Fig. 2.  A "natural color" composite (same as in Fig. 2) from this image appears in the top left panel of Fig. 3, with a digital camera image of the same scene in the upper right panel.  The second hyperspectral image was acquired of a sub-area of the first scene, with telescope movements of only 4.25 mrad (1/4 of the field-of-view) between pixels.  The lower left panel of Fig. 3 shows this sub-frame properly located within the first image, using the same color composite.  Note that several rocks, not well-resolved in the original image, are clearly defined in the superresolution subframe.  We believe use of this technique may substantially enhance the value of data acquired by the Mini-TES, especially on the 2001 lander, where the instrument will stay in a fixed location for the duration of the mission.             Figure 3 Future work:  With our technique for collection of hyperspectral images now honed, our next goal is to try to understand the best way to utilize synergies between hyperspectral cubes acquired by the Mini-TES and imaging data that will be acquired by the panoramic stereo camera system (PANCAM) on the Mars landers and rovers.  For example, one significant difference between horizontal-viewing hyperspectral images of a landscape and more typical downwardviewing hyperspectral images is that horizontalviewing images will tend to have much greater depthof-field from the foreground to the horizon.  Because of this, a more sophisticated pixel-by-pixel atmospheric correction will need to be applied to the spectra comprising the image.  One way to determine the atmospheric pathlength to any given pixel will be to derive it from stereoscopic images of the same scene.  Another synergy we will investigate is fusion of hyperspectral and camera data from the same scene to produce images with textures provided by the cameras and colors provided by processing and classification of  hyperspectral data.   References: [1] Squyres, S.W., et al. (1999) LPSC XXX, #1672, [2] Squyres, S.W., et al. (2000) manuscript in prep., [3] Stoker, C.R. et al. (1999) JGR, 104.  
