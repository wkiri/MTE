 MARSMAP: AN INTERACTIVE  VIRTUAL REALITY MODEL OF THE PATHFINDER LANDING SITE C. Stoker, T. Blackmon, J. Hagen, B. Kanefsky, D. Rasmussen,  K. Schwehr, M. Sims, E. Zbinden, NASA Ames  Research Center, Moffett Field, CA 94305-1000. The Pathfinder mission  made use of a unique capability to rapidly generate and interactively display three-dimensional photo-realistic virtual reality (VR) models of the Martian surface. Marsmap, the interactive terrain visualization system developed for  Pathfinder by the authors as part of a participating science project, creates and renders digital terrain models produced from stereo images of Mars' surface taken by the lander's IMP camera.  A primary benefit of using VR to display geologic information is that it provides an improved perception of depth and spatial layout of the remote site.  The VR aspect of the display allows an operator to move freely in the environment, unconstrained by the physical limitations of the perspective from which the data were acquired.  Virtual Reality also offers a way to archive and retrieve information in a way that is easily understood. Combining the VR models with stereo display systems can enable a  feeling of presence at the remote  location.   The capability, implemented in Marsmap, to interactively perform measurements from within the VR model offered unprecedented ease in performing operations that are normally time consuming and difficult using standard photogrametric techniques.  This ground-breaking project demonstrated the power of using Virtual Reality as a cartographic tool. 3-D MODEL PRODUCTION The Stereo Pipeline The rapid production of VR models used  a computational algorithm called  the "stereo pipeline".  The core component of the stereo pipeline is the automatic matching of features in the left eye camera image with the same features in the right eye camera image, thus providing  the necessary correspondence to compute a 3-D location for the feature.  Using one image of a stereo pair as a reference,  a "kernel" image area is selected around each pixel. This kernel is compared to the other stereo  image (by sliding the kernel across the test image in increments of 1 pixel) to find the  most similar match.  The disparity, the difference between the position of the kernel and the match, is computed for each pixel for which a match is found. Multipass cross-correlation is used to  minimize the number of non-matches but some occur due primarily to image borders. Using the known camera pointing geometry and optical characteristics of IMP,  the disparity values are used to calculate a set of object points  in 3 dimensions which,  when connected, form the vertices of a polygonal mesh.  For the Pathfinder mission, 3-D models were generated at a resolution of 4x4 (1 vertex every 4 pixels in both azimuth and elevation directions) and 8x12. Finally, the original image is used as a texture map for the 3-D  polygonal mesh. Remote  Production of  the Model A significant aspect of our project was the rapid production and display of models using a distributed production team and fast data transfer.  As images of Mars arrived at Jet Propulsion Laboratory JPL (Pasadena, CA)  through the Deep Space Network, they were automatically transferred to NASA Ames (San Jose, CA) where  3-D models were produced.   After processing, the 3-D models were transmitted back to computers at JPL for display. The time to process a single pair of IMP stereo images into a 3-D model was less than 25 seconds (1).  The fist complete stereo panorama sequence taken after  deployment of the IMP, known as the `Monster Pan' was comprised of 98  stereo pairs.  This data were displayed in virtual reality at mission control within one hour of downlink. MARSMAP VR DISPLAY INTERFACE Marsmap (2) is a software package developed to display the Pathfinder VR models which include the following key features: . Real-time, interactive navigation of the virtual viewpoint through the 3-D  model of the landing site; . Measurement of topographical features, including 3-D positions, distances, and angles; .  Display of daily traverses of Sojourner; .  Display of rover images within the VR model projected from the viewpoint of the rover; .  Catalog and display of  the sequence and location of science experiments conducted by the  rover. MarsMap was designed to be accessed with a standard 2-D mouse and used pull-down menus to call features as described below.  Models could be viewed in stereo using Stereographics CrytalEyes LCD shutter glasses or with a set of head tracked "Virtual Binoculars" (3) The main Marsmap features are discussed in more detail next. View Control Several  modes of motion control are available including: Drive mode: most useful for navigating close to the surface, a user can move around the model at a constant elevation. Anchor mode: allows the user to select and move with respect to an "anchor" point in the model. The   user can zoom (towards or away) from the selected anchor   point, as well as rotate (horizontally or vertically) around the  point. Dome  mode: allows the user to enter azimuth and elevation coordinates  that  anchor the  viewpoint as if looking from the IMP camera in the specified direction. An overlay can be super-imposed over the model to display compass headings for direction of the viewpoint as well as VIRTUAL REALITY ON PATHFINDER:  C. Stoker et al. text of the viewpoint position and current  navigational mode. Measurement Tools Marsmap contained user-operated virtual tools  to interactively obtain   3-D positions,  distances, and angles. All measurement tools were based upon a 3-D cursor graphically representing  orthogonal axes aligned with the Mars local level coordinate frame.  The 3-D   cursor was designed to follow the 2-D   mouse cursor on the screen and intersect the front-most polygon in the VR model to yield its 3-D position. Map Markers MarsMap provides capability to place icons ( 3-D overlays) in the model which can be toggled on/off using a pull-down menu.  External data files containing user-defined characteristics (shape, size, location, associated text) are read by Marsmap. The map markers were used to display the location and sequence of Sojourner science experiments, and to display names and locations of the most prominent rocks  at the site, and to display the estimated traverse path of the rover using "dead reckoning". Sojourner Positions Sojourner position and heading information, as determined after each traverse using IMP images, was represented in MarsMap by placing a CAD model of the rover into the VR model at the appropriate position. Sojourner Images Images from the Sojourner rover cameras were integrated into the VR models as 2-D billboards projected   from the rover's point-of-view.  Using the rover position and heading information from telemetry readings,   and the image size, a 2-D projection window is defined in the 3-D  model.  The Sojourner image is then placed in the model at the  projection window, along with a CAD model of the Sojourner at that  position and heading. USES OF MARSMAP MODELS Beyond the spectacular visualization capabilities for   navigating Mars in 3-D using stereo eye wear and virtual reality goggles,   MarsMap provided the Pathfinder team with a valuable tool for performing mission planning and operations, science analysis, and public outreach.  A few examples of its use are summarized here. Mission Operations and Planning: Early in the mission, Marsmap was used to measure the angles of the ramps used for deploying the rover, to help determine whether the rover could be safely deployed. Marsmap was used to plan Sojourner traverses and determine the best places to deploy the APX.  The angle measuring capability  was used to determine that Sojourner could not approach Yogi from the IMP-facing side due to an overhang that is only obvious using the reprojection capabilities of Marsmap.  Marsmap was also used to help with long range rover path planning.  A proposed traverse would be explored in "Drive" mode at the height of the rover wheels to assess hazards.  Once a traverse was planned, the target traverse was archived in Marsmap using map markers.  The heads-up display of Marsmap was used to retrieve local lander coordinates for target rocks.  These coordinates were needed to command the IMP to image particular rocks. Science Analysis: The measurement and display capabilities of Marsmap, along with the ability to reproject the image data to a new perspective, allowed normally difficult measurements to be made easily.  During the mission, science team members used Marsmap to measure the direction of over 300 small windstreaks which occurred behind rocks.  These measurements allowed a determination of the prevailing wind direction (4).  Marsmap was also used to measure the dimensions of over 2500 rocks at the landing site (4).  From these measurements, the statistics of rock size distribution on the Martian surface have been determined. Outreach: During the 30 day prime Pathfinder mission, Marsmap was demonstrated hundreds of times to various individuals, groups, and members of the press who toured Pathfinder mission operations.  Within one hour of landing, California Governor Pete Wilson and NASA Administrator Dan Goldin had a virtual presence on Mars.  The strong sense of presence afforded by VR gives it great public appeal. CONCLUSIONS The Marsmap project has shown that virtual reality can be used as a powerful method for analyzing the geology of a remote environment.  VR models can be created and displayed and analysis and measurements can be performed with unprecedented speed and accuracy.  Virtual Reality may represent a giant leap forward in cartographic technique. (1) Processing was performed on a dual processor Octane (2 195 MHZ RS10000, 256 MB RAM) from Silicon Graphics, Inc. (2) MarsMap was written using C programming language and the World ToolKit   VR software libraries from Sense8 Corporation.  Running on a Silicon   Graphics InfiniteReality2 computer (2 195 MHZ RS10000 processors, 512   MB RAM, 64 MB texture memory), images were rendered at 30 frames per   second (approximately), which allowed the user to move smoothly though the   interactive model of the Mars environment. (3) A product from N-vision.  Head tracking for the binoculars was implemented using an inertial sensor from InterSense Corp. (4) Smith et al., Results from the Mars Pathfinder Camera, Science Vol 287, 1758, 1997. 
