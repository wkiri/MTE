 GAUSSIAN NOISE REMOVAL FOR WET CHEMISTRY DATA FROM THE PHOENIX MISSION   Y. Mu1, W. Ding1, X. Ren1, E. Oberlin2, S. Kounaves2, 1 Department of Computer Science, University of Massachusetts Boston, 100 Morrissey Blvd., Boston, MA 02125 (yangmu@cs.umb.edu, ding@cs.umb.edu, xiangren2000@gmail.com), 2Department of Chemistry, Tufts University, 62 Talbot Avenue, Medford, MA 02155 (elizabeth.oberlin@tufts.edu, samuel.kounaves@tufts.edu).  Introduction:  The Wet Chemistry Laboratory (WCL) on board the Phoenix lander performed the first comprehensive wet chemical analysis of the soil on Mars, during the summer of 2008. Each WCL consisted of a lower cell whose walls were lined with an array of sensors and an upper assembly for adding water, reagents, soil, and stirring. The sensor array included ion selective electrodes (ISE) for K+, Na+, Mg+, Ca+, etc and electrodes for conductivity, redox potential, cyclic voltammetry, chronopotentiometry, and an PH electrode [1]. The initial in-situ chemical analysis of the four soil samples delivered to the WCL provided concentrations of the soluble ionic species in the soil along with the pH and conductivity[2].  Even though at first the results appeared to present a simple picture of the soluble soil chemistry, it has become clearly evident that the analyses were complicated by an unplanned titration of the soil/water mixture with barium chloride, the presence of chemical species whose signal was convoluted into other sensor readings, and the effects of temperature and noise.  The combined effect of these interferences has put into question some of the concentrations and identities of the ionic species that were measured.  Use of such incorrect values in conjunction with chemical speciation modeling programs could result in misinterpretation of the minerals and parent salts present in  the soil analyzed by the Phoenix WCL.  To obtain correct sensor readings for conversion to concentrations, and to identify other chemical species present, will require a combination of complex processing/analysis of the returned WCL data, parallel laboratory analyses using the remaining two WCL flight spare units, and equilibrium modeling to validate such results. In this paper, we report on our investigation of a promising strategy to address the aforementioned problem. Our strategy consists of developing and implementing of a new methodology using a Bayesian Least Square estimator on signal denoising, a fuzzy sequence pattern matching approach on white noise removal.  Methodology: We propose to  perform denoising in the Wavelet domain instead of the original signal domain in order to take full advantage of statistical image modeling, as shown in Figure 1. The signal data will be first transformed into a 2D matrix, and then the matrix will be decomposed into pyramid subbands at difference scales in the Wavelet domain. Denoising will be performed at each subband. Finally, we will invert the pyramid transformation and obtain the denoised signal.  Our technical approach to Bayesian white noise denoising for signal processing relies on a set of techniques taken from computer vision and statistics. For any noise input signal vector y‚Éë = [a1, a2, ‚ãØ an], we propose a new method denoted as Bayesian Probability Mapping. Specifically, the n samples are quantized into d bins according to the input value range. i.e.,  a1 is quantized into bin b1, which means a1 has a probability of 1 to fall into this bin. Therefore, the input signal could be converted to a probability matrix  P ‚àà ‚Ñùd√ón . The d √ó n  matrix is then transformed into the wavelet domain using a set of multiscale bandpass orthogonal filters. In our previous work on crater detection from HRSC images [3], wavelets have proved to be a very powerful tool for pattern analysis because wavelet decomposition can efficiently enhance statistical features of images.  In this project, we will exploit dependencies between Wavelet coefficients based on Gaussian scale mixtures. It has been observed that most responses of the subband of the Wavelet filter have a near zero value because most of the matrix entries are either not data entries or simply random noise data. A portion of the signal response that corresponds to the real signal has comparatively large amplitude responses.  For the WCL data, we propose to model local clusters of wavelet coefficients of a pyramid subband using Gaussian Scale Mixtures. A random vector ùë•  is a Gaussian scale mixture if and only if it is expressed as ùë• = ‚àöùúÜÔøΩ‚ÉëÔøΩ , where ÔøΩ‚ÉëÔøΩ   is  a zero-mean Gaussian vector, ùúÜ is an independent positive scalar random variable, and here = indicates equality in distribution.  We then calculate the local neighborhood noise covariance ùê∂ùë§ and the observed signal in Wavelet domain local neighborhood covariance Cy . ùê∂ùë§ can be computed by averaging the products pairs of coefficients over all local neighborhoods of the subband.  Bayesian Least Squares estimate can be written as [4]: E{x y, Œª}  = ‚à´E{x y, Œª}p(Œª y)dŒª  = Œª(Cy ‚àí Cw)(Œª(Cy ‚àí Cw) + Cw) ‚àí1 y,  where  E{x y, Œª} is the estimated Wavelet coefficients of the denoised signal.  The last step is the standard routine in image denoising by inverting the pyramid subbands to produce the denoised sensor data. A major branch on existing signal denoising methods relies on user-defined parameters, i.e., the thresholds of noise filters. However in the WCL data, we cannot validate the parameter settings with ground truth data. Thus the proposed nonparametric Bayesian probability approach is a natural choice to be examined.    Results: First, we performed simulations with white Gaussian noises with a standard deviation of 0.5 added to the standard Sine function (see Figure 2). We then applied our algorithm to this noise signal.  The result shows that the denoised Sine function using our proof-of-concept algorithm matches well with ground truth, which confirms our assumption for the proposed approach on the white noise denoising.  Second, we used this algorithm on Li+, pHA, IrpH, and Na+ of the WCL data for sol 30 (see Figure 3). Compared to the WCL data before denoising, the denoised signals show a clear trend and also preserve intervals which represent different phases of the chemical experiment. In Figure 3, we can see that pHA, IrpH and Na+ produce a dramatic fluctuation at about 2000 and 4000 Mars log time, which is caused by the addition of the calibrant crucible and soil sample, whereas Li+ remained stable during the whole process.  Thus, the Li+ ISE was used as a reference by subtracting its reading before the analysis.  Conclusion: In this project, we proposed an approach using Bayesian least squares estimation to remove white noise influence from the WCL data. We have conducted experiments on synthetic added Gausian noise data and WCL ISE data from to evaluate our algorithm. The results demonstrate that white noise has been removed by using this approach. This approach appears to be very promising and is currently being applied to further denoise the Phoenix WCL sensor data.  Acknowledgements: This work was supported by NASA under Grant NNX13AJ69G.  References: [1] Kounaves, S. P., et al., (2009) J. Geophys. Res.,114, E00A19. [2] Kounaves, S. P., et al., (2010) J. Geophys. Res.,115, E00E10. [3] Ding, W. et al. (2011) Transactions on Intel-ligent Systems and Technology, Vol. 2, Issue 4, July. [4] Portilla, J. et al, (2003) IEEE Transactions on Image Processing, 12(11), 1338-1351.  Figure 1. Bayesian Least Squares estimator denoising of the Cl- ISE signal for Sol 30 data.  Figure 2. An example illustrating denoising of a Sine function.  Figure 3. Denoising results for the  pHA, IrpH and Na+ ISE sensor data.  <127.5, 133.1, ‚Ä¶,243.4> Bayesian Least Square Estimator in the Wavelet domain Bayesian Probability Mapping Wavelet decomposition Reconstruct the denoised signal (1) (2) (3) (4) 
